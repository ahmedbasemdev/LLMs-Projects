{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install bitsandbytes peft transformers datasets trl","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:07:13.849635Z","iopub.execute_input":"2024-07-30T09:07:13.850042Z","iopub.status.idle":"2024-07-30T09:07:37.011789Z","shell.execute_reply.started":"2024-07-30T09:07:13.850008Z","shell.execute_reply":"2024-07-30T09:07:37.010503Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nCollecting trl\n  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.32.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nCollecting tyro>=0.5.11 (from trl)\n  Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nCollecting docstring-parser>=0.16 (from tyro>=0.5.11->trl)\n  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nDownloading bitsandbytes-0.43.2-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.5-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\nDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, docstring-parser, tyro, bitsandbytes, trl, peft\n  Attempting uninstall: docstring-parser\n    Found existing installation: docstring-parser 0.15\n    Uninstalling docstring-parser-0.15:\n      Successfully uninstalled docstring-parser-0.15\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.43.2 docstring-parser-0.16 peft-0.12.0 shtab-1.7.1 trl-0.9.6 tyro-0.8.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport random\nimport matplotlib.pyplot as plt\nfrom datasets import Dataset, load_dataset\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nimport logging\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-30T09:08:03.200778Z","iopub.execute_input":"2024-07-30T09:08:03.201904Z","iopub.status.idle":"2024-07-30T09:08:10.902347Z","shell.execute_reply.started":"2024-07-30T09:08:03.201866Z","shell.execute_reply":"2024-07-30T09:08:10.901207Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"huggingface_dataset_name = \"cnn_dailymail\"\ndataset = load_dataset(huggingface_dataset_name, \"3.0.0\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:08:10.904280Z","iopub.execute_input":"2024-07-30T09:08:10.904826Z","iopub.status.idle":"2024-07-30T09:08:46.019150Z","shell.execute_reply.started":"2024-07-30T09:08:10.904796Z","shell.execute_reply":"2024-07-30T09:08:46.018118Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a7bc0b2938a40189610518e0dd9232e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e24bcb0719641679879a32e342956bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"647e6fd9ba954030bbee339476c40461"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd92437ade414bd593418fd0e896b111"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fdd1ad515e245abbe33582a5ea98baa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d9402105814abfb0fcd73a98b9f1af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da958e392b894b718f6816fdb0c5bdcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a8b553ba5b74222b8afb6c9b47efdc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7bd6bc22d0a449a83345535fd5170d8"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 287113\n    })\n    validation: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 13368\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 11490\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"sample = dataset['train'][0]\nprint(f\"\"\"Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\"\"\")\nprint(sample[\"article\"][:500])\nprint(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\nprint(sample[\"highlights\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:08:46.021270Z","iopub.execute_input":"2024-07-30T09:08:46.021625Z","iopub.status.idle":"2024-07-30T09:08:46.031990Z","shell.execute_reply.started":"2024-07-30T09:08:46.021594Z","shell.execute_reply":"2024-07-30T09:08:46.030965Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Article (excerpt of 500 characters, total length: 2527):\nLONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as s\n\nSummary (length: 217):\nHarry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\nYoung actor says he has no plans to fritter his cash away .\nRadcliffe's earnings from first five Potter films have been held in trust fund .\n","output_type":"stream"}]},{"cell_type":"code","source":"def format_instruction(dialog: str, summary:str):\n    instruction = f\"\"\"### Instruction:\n    summarize the following conversation.\n    \n    ### input:\n    {dialog.strip()}\n    \n    ### summary:\n    {summary}\n    \n    \"\"\".strip()\n    \n    return instruction\n\ndef generate_instruction_dataset(data_point):\n    return {\n        \"article\": data_point[\"article\"],\n        \"highlights\": data_point[\"highlights\"],\n        \"text\": format_instruction(data_point[\"article\"],data_point[\"highlights\"])\n    }\n\ndef procces_dataset(data : Dataset):\n    \n    return (\n    data.shuffle(seed=42).map(generate_instruction_dataset).remove_columns(['id'])\n    )","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:08:46.033374Z","iopub.execute_input":"2024-07-30T09:08:46.033736Z","iopub.status.idle":"2024-07-30T09:08:46.043611Z","shell.execute_reply.started":"2024-07-30T09:08:46.033708Z","shell.execute_reply":"2024-07-30T09:08:46.042696Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset['train'] = procces_dataset(dataset['train'])\ndataset[\"test\"] = procces_dataset(dataset[\"validation\"])\ndataset[\"validation\"] = procces_dataset(dataset[\"validation\"])\n\ntrain_data = dataset['train'].shuffle(seed=42).select([i for i in range(1000)])\n\n# Select 100 rows from the test and validation splits\ntest_data = dataset['test'].shuffle(seed=42).select([i for i in range(100)])\nvalidation_data = dataset['validation'].shuffle(seed=42).select([i for i in range(100)])\n\ntrain_data,test_data,validation_data\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:08:46.045766Z","iopub.execute_input":"2024-07-30T09:08:46.046122Z","iopub.status.idle":"2024-07-30T09:09:40.772871Z","shell.execute_reply.started":"2024-07-30T09:08:46.046095Z","shell.execute_reply":"2024-07-30T09:09:40.771571Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3fcd2b3a8f54a449ba54b2fe5f62ab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e7f7668564740938a99186040c3b0e7"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['article', 'highlights', 'text'],\n     num_rows: 1000\n }),\n Dataset({\n     features: ['article', 'highlights', 'text'],\n     num_rows: 100\n }),\n Dataset({\n     features: ['article', 'highlights', 'text'],\n     num_rows: 100\n }))"},"metadata":{}}]},{"cell_type":"code","source":"model_id =  \"NousResearch/Llama-2-7b-hf\"\n\nbnb_config = BitsAndBytesConfig(\n    # Enabling 4-bit quantization for the model\n    load_in_4bit=True,\n    \n    # Using double quantization, which can help improve the precision and reduce the memory footprint\n    bnb_4bit_use_double_quant=True,\n    \n    # Setting the quantization type to \"nf4\" (Normalized Float 4), a specific type of 4-bit quantization\n    bnb_4bit_quant_type=\"nf4\",\n    \n    # Setting the data type used for computation to bfloat16 (Brain Float 16), which balances precision and performance\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\n# Loading a pre-trained causal language model with the specified quantization configuration\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,           # The ID or path of the pre-trained model\n    quantization_config=bnb_config,  # Applying the previously defined quantization configuration\n    device_map=\"auto\"   # Automatically mapping the model to available devices (e.g., CPU, GPU)\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:09:40.777719Z","iopub.execute_input":"2024-07-30T09:09:40.779172Z","iopub.status.idle":"2024-07-30T09:14:57.464402Z","shell.execute_reply.started":"2024-07-30T09:09:40.779130Z","shell.execute_reply":"2024-07-30T09:14:57.463079Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2fab2e3b50e4e358bcbc9420400f747"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b84642b7534626965b436d01280678"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44369d7ac5054bcba5d4c312957c1ac9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c152e8def4a241439b1841d1f9dfc020"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5de8b282aa9412a9fb457aa80c93501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdf4877db69e4caf836e2ee1c64d7a1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0498ea62a1144f14b45799ed5d097af7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"621a78f217f242c5b5075b5737ab52a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed7e7d76894740b8ae6acdd4d1784ec3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d5aa36438714eca9d7ac1be290d8908"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2047c92061cb4ccb93329f5f4a29c7c5"}},"metadata":{}}]},{"cell_type":"markdown","source":"## ZERO-SHOT INFERENCE WITH LLAMA-2 7B¶\n","metadata":{}},{"cell_type":"code","source":"index = 2\n\ndialogue = test_data['article'][index]\nsummary = test_data['highlights'][index]\n\nprompt = f\"\"\"\nSummarize the following conversation.\n\n### input:\n{dialogue}\n\n### summary\n{summary}\n\"\"\"\n\ninputs = tokenizer(prompt, return_tensors='pt')\nmodel_output = model.generate(inputs['input_ids'],\n                             max_new_tokens=100,\n                             )\noutput = tokenizer.decode(model_output[0], skip_speical_tokens=True)\n\ndash_line = '-'.join('' for x in range(50))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{prompt}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:14:57.466210Z","iopub.execute_input":"2024-07-30T09:14:57.466959Z","iopub.status.idle":"2024-07-30T09:15:25.171101Z","shell.execute_reply.started":"2024-07-30T09:14:57.466918Z","shell.execute_reply":"2024-07-30T09:15:25.169894Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-07-30 09:15:03.599171: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-30 09:15:03.599317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-30 09:15:03.734664: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"-------------------------------------------------\nINPUT PROMPT:\n\nSummarize the following conversation.\n\n### input:\nA federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to do so. The court's order on Thursday came as the school found itself amid a racial controversy after video of fraternity students engaged in a racist chant spread across the Internet. Dr. Leone-Noelle Meyer maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France . University President David Boren ordered a fraternity house closed and expelled two of its members after reviewing clips of the chant that referenced lynching and said blacks would never be allowed in the fraternity. The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris. She maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France. Her father, Raoul Mayer, died in 1970. Swiss records show Meyer's father in Paris had owned the painting. But a Swiss court ruled that the painting's post-war owners had properly established ownership and rejected her claim. Bequeathed to OU by Clara Weitzenhoffer, the wife of oil tycoon Aaron Weitzenhoffer, the school displayed it publicly for over a decade. The painting: Swiss records show Leone-Noelle Meyer's father in Paris had owned the painting 'Shepherdess Bringing in Sheep' by Camille Pissaro . Disputed item: This Monday, May 12, 2014 photo shows a display of information on the 1886 painting 'Shepherdess Bringing in Sheep' by Camille Pissarro . The Weitzenhoffers bought the painting from a New York gallery in 1956. When she died in 2000, she donated more than 30 works worth about $50 million to the University of Oklahoma. In an emailed statement Saturday, Oklahoma University spokeswoman Catherine F. Bishop said: 'The University is continuing its efforts to work with the plaintiffs to determine all the facts in this matter, some of which may still be unknown, and to seek a mutually agreeable resolution.' Last year, Boren defended Oklahoma University's ownership, saying the school does not want to keep any items it does not legitimately own but also wants to avoid a bad precedent by automatically giving away gifts it receives to anyone who claims them. Boren and the school have opposed the lawsuit on largely procedural grounds, saying the school has sovereign immunity and that Meyer was not diligent in pursuing her claim and had sued in New York rather than Oklahoma as a 'forum shopping strategy' to avoid Oklahoma's more restrictive statute of limitations. Several Oklahoma lawmakers who authored a resolution in the state Legislature seeking to force the school to turn the painting over have spoken out against the university's position. In a letter to the people of Oklahoma, Meyer has said her quest 'has nothing to do with money. It is about justice and a duty to remember.' Pierre Ciric, a lawyer for Meyer, said Saturday he welcomed 'any progress toward the resolution of our client's claim.' 'It appears that everyone involved with this case agrees that `La Bergere' was the property of my client's father prior to the Nazi occupation of France, which we have asserted since the complaint was filed,' he said. Under fire: The court's order on Thursday came as the school found itself amid a racial controversy after video showing Sigma Alpha Epsilon members singing a racist chant while traveling on a tour bus went viral .\n\n### summary\nThe court's order after video of fraternity students at the school engaged in a racist chant spread across the Internet .\nThe school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris .\nMeyer says she entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis .\nSwiss records show Meyer's father, Raoul Meyer,  had owned the painting in Paris .\n\n-------------------------------------------------\nBASELINE HUMAN SUMMARY:\nThe court's order after video of fraternity students at the school engaged in a racist chant spread across the Internet .\nThe school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris .\nMeyer says she entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis .\nSwiss records show Meyer's father, Raoul Meyer,  had owned the painting in Paris .\n\n-------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n<s> \nSummarize the following conversation.\n\n### input:\nA federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to do so. The court's order on Thursday came as the school found itself amid a racial controversy after video of fraternity students engaged in a racist chant spread across the Internet. Dr. Leone-Noelle Meyer maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France . University President David Boren ordered a fraternity house closed and expelled two of its members after reviewing clips of the chant that referenced lynching and said blacks would never be allowed in the fraternity. The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris. She maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France. Her father, Raoul Mayer, died in 1970. Swiss records show Meyer's father in Paris had owned the painting. But a Swiss court ruled that the painting's post-war owners had properly established ownership and rejected her claim. Bequeathed to OU by Clara Weitzenhoffer, the wife of oil tycoon Aaron Weitzenhoffer, the school displayed it publicly for over a decade. The painting: Swiss records show Leone-Noelle Meyer's father in Paris had owned the painting 'Shepherdess Bringing in Sheep' by Camille Pissaro . Disputed item: This Monday, May 12, 2014 photo shows a display of information on the 1886 painting 'Shepherdess Bringing in Sheep' by Camille Pissarro . The Weitzenhoffers bought the painting from a New York gallery in 1956. When she died in 2000, she donated more than 30 works worth about $50 million to the University of Oklahoma. In an emailed statement Saturday, Oklahoma University spokeswoman Catherine F. Bishop said: 'The University is continuing its efforts to work with the plaintiffs to determine all the facts in this matter, some of which may still be unknown, and to seek a mutually agreeable resolution.' Last year, Boren defended Oklahoma University's ownership, saying the school does not want to keep any items it does not legitimately own but also wants to avoid a bad precedent by automatically giving away gifts it receives to anyone who claims them. Boren and the school have opposed the lawsuit on largely procedural grounds, saying the school has sovereign immunity and that Meyer was not diligent in pursuing her claim and had sued in New York rather than Oklahoma as a 'forum shopping strategy' to avoid Oklahoma's more restrictive statute of limitations. Several Oklahoma lawmakers who authored a resolution in the state Legislature seeking to force the school to turn the painting over have spoken out against the university's position. In a letter to the people of Oklahoma, Meyer has said her quest 'has nothing to do with money. It is about justice and a duty to remember.' Pierre Ciric, a lawyer for Meyer, said Saturday he welcomed 'any progress toward the resolution of our client's claim.' 'It appears that everyone involved with this case agrees that `La Bergere' was the property of my client's father prior to the Nazi occupation of France, which we have asserted since the complaint was filed,' he said. Under fire: The court's order on Thursday came as the school found itself amid a racial controversy after video showing Sigma Alpha Epsilon members singing a racist chant while traveling on a tour bus went viral .\n\n### summary\nThe court's order after video of fraternity students at the school engaged in a racist chant spread across the Internet .\nThe school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris .\nMeyer says she entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis .\nSwiss records show Meyer's father, Raoul Meyer,  had owned the painting in Paris .\nBut a Swiss court ruled that the painting's post-war owners had properly established ownership and rejected her claim .\n\n### 2014-05-17\n\n### input:\n\nThe US Supreme Court on Friday refused to hear a case involving a 75-year-old Holocaust survivor's lawsuit against the University of Oklahoma over a painting she says was stolen from her father by the Nazis. The high\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### TRAINING STEP (FINE TUNING)¶\n","metadata":{}},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\ndef print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:15:25.172585Z","iopub.execute_input":"2024-07-30T09:15:25.173375Z","iopub.status.idle":"2024-07-30T09:15:25.286648Z","shell.execute_reply.started":"2024-07-30T09:15:25.173241Z","shell.execute_reply":"2024-07-30T09:15:25.285682Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### LoRA (Low-Rank Adaptation) :\nis a technique for Parameter-Efficient Fine-Tuning (PEFT) that adds trainable low-rank matrices to the model weights.\n\n![LoRa](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/133_trl_peft/step2.png)\n","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nlora_config = LoraConfig(\n    # The scaling factor for the low-rank approximation. Higher values allow \n    # for capturing more details but increase computation.\n    r=16,\n    \n    # The scaling factor for the learning rate. This helps control how \n    # aggressively the model adapts to the learning rate.\n    lora_alpha=64,\n    \n    # A list of module names within the model to which the LoRA (Low-Rank Adaptation)\n    # method will be applied. Here, it targets the projection layers.\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    \n    # The dropout rate applied to the LoRA layers to prevent overfitting.\n    lora_dropout=0.1,\n    \n    # Specifies whether or not to apply the LoRA method to the bias terms in the model.\n    # Here, \"none\" means no bias adaptation.\n    bias=\"none\",\n    \n    # Specifies the type of task the model is being used for. \n    # \"CAUSAL_LM\" stands for Causal Language Modeling, indicating that this configuration \n    # is for a task where the model predicts the next word in a sequence.\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, lora_config)\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:15:25.287910Z","iopub.execute_input":"2024-07-30T09:15:25.288208Z","iopub.status.idle":"2024-07-30T09:15:26.204479Z","shell.execute_reply.started":"2024-07-30T09:15:25.288183Z","shell.execute_reply":"2024-07-30T09:15:26.203414Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"trainable params: 16777216 || all params: 3517190144 || trainable%: 0.477006226934315\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nOUTPUT_DIR = \"llama2-docsum-adapter\"\n\ntraining_arguments = TrainingArguments(\n    # Set the batch size per device (GPU/CPU) during training\n    per_device_train_batch_size=4,\n    \n    # Number of gradient accumulation steps. This effectively increases the batch size\n    # by accumulating gradients over multiple steps before updating the model.\n    gradient_accumulation_steps=4,\n    \n    # Specify the optimizer to use. Here, 'paged_adamw_32bit' is a variant of AdamW \n    # optimizer suitable for training with lower precision.\n    optim=\"paged_adamw_32bit\",\n    \n    # How often to log training information (e.g., loss). Here, it logs every step.\n    logging_steps=1,\n    \n    # Set the learning rate for the optimizer.\n    learning_rate=1e-4,\n    \n    # Enable 16-bit floating-point precision training to reduce memory usage and speed up training.\n    fp16=True,\n    \n    # Maximum gradient norm for gradient clipping to prevent exploding gradients.\n    max_grad_norm=0.3,\n    \n    # Number of epochs to train the model.\n    num_train_epochs=1,\n    \n    # Evaluation strategy to use during training. 'steps' means evaluation is performed every few steps.\n    evaluation_strategy=\"steps\",\n    \n    # Number of steps between evaluations. Here, it's set to 0.2 steps (interpreted as every 20% of an epoch).\n    eval_steps=0.2,\n    \n    # Fraction of training steps used for warming up the learning rate scheduler.\n    warmup_ratio=0.05,\n    \n    # Strategy to use for saving the model checkpoints. 'epoch' means saving at the end of every epoch.\n    save_strategy=\"epoch\",\n    \n    # Whether to group samples of similar lengths together to improve training efficiency.\n    group_by_length=True,\n    \n    # Directory to save the training outputs (model checkpoints, logs, etc.).\n    output_dir=OUTPUT_DIR,\n    \n    # Specify the tool to use for logging and reporting. Here, it uses TensorBoard.\n    report_to=\"tensorboard\",\n    \n    # Save the model in safetensors format, which is more secure and efficient.\n    save_safetensors=True,\n    \n    # Learning rate scheduler type. 'cosine' implies a cosine annealing schedule for the learning rate.\n    lr_scheduler_type=\"cosine\",\n    \n    # Seed for random number generators to ensure reproducibility.\n    seed=42,\n)\n\n# Disable caching during training to avoid potential issues or warnings.\nmodel.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:15:26.205923Z","iopub.execute_input":"2024-07-30T09:15:26.206245Z","iopub.status.idle":"2024-07-30T09:15:26.263181Z","shell.execute_reply.started":"2024-07-30T09:15:26.206216Z","shell.execute_reply":"2024-07-30T09:15:26.262080Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\n\ntrainer = SFTTrainer(\n    # The model to be trained\n    model=model,\n    # The dataset used for training the model\n    train_dataset=train_data,\n    # The dataset used for evaluating the model during training\n    eval_dataset=validation_data,\n    # The PEFT (Parameter-Efficient Fine-Tuning) configuration, here using LoRA (Low-Rank Adaptation)\n    peft_config=lora_config,\n    # The name of the field in the dataset that contains the text data\n    dataset_text_field=\"text\",\n    # The maximum sequence length for input data. Inputs longer than this will be truncated.\n    max_seq_length=1024,\n    # The tokenizer used for processing the text data into tokens that the model can understand\n    tokenizer=tokenizer,\n    # The training arguments that define various training parameters and configurations\n    args=training_arguments,\n)\n\n# Start the training process using the specified trainer instance\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-30T09:15:26.266225Z","iopub.execute_input":"2024-07-30T09:15:26.266566Z","iopub.status.idle":"2024-07-30T11:00:11.945233Z","shell.execute_reply.started":"2024-07-30T09:15:26.266537Z","shell.execute_reply":"2024-07-30T11:00:11.944131Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0c993456987408e94b656d71eca557c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a4f088d6e99453690425310bdf98378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [62/62 1:42:56, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>13</td>\n      <td>1.613100</td>\n      <td>1.706264</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.668000</td>\n      <td>1.671105</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.647700</td>\n      <td>1.663563</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.821900</td>\n      <td>1.661522</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=62, training_loss=1.703748187711162, metrics={'train_runtime': 6276.621, 'train_samples_per_second': 0.159, 'train_steps_per_second': 0.01, 'total_flos': 3.477409070560051e+16, 'train_loss': 1.703748187711162, 'epoch': 0.992})"},"metadata":{}}]},{"cell_type":"code","source":"peft_model_path=\"./peft-dialogue-summary\"\n\ntrainer.model.save_pretrained(peft_model_path)\ntokenizer.save_pretrained(peft_model_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:00:11.946778Z","iopub.execute_input":"2024-07-30T11:00:11.947890Z","iopub.status.idle":"2024-07-30T11:00:12.293214Z","shell.execute_reply.started":"2024-07-30T11:00:11.947853Z","shell.execute_reply":"2024-07-30T11:00:12.292296Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"('./peft-dialogue-summary/tokenizer_config.json',\n './peft-dialogue-summary/special_tokens_map.json',\n './peft-dialogue-summary/tokenizer.model',\n './peft-dialogue-summary/added_tokens.json',\n './peft-dialogue-summary/tokenizer.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"### INFERENCE","metadata":{}},{"cell_type":"code","source":"from transformers import TextStreamer\n\nmodel.config.use_cache = True\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:00:12.294481Z","iopub.execute_input":"2024-07-30T11:00:12.294917Z","iopub.status.idle":"2024-07-30T11:00:12.324127Z","shell.execute_reply.started":"2024-07-30T11:00:12.294883Z","shell.execute_reply":"2024-07-30T11:00:12.323292Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm()\n            (post_attention_layernorm): LlamaRMSNorm()\n          )\n        )\n        (norm): LlamaRMSNorm()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from peft import AutoPeftModelForCausalLM\nfrom transformers import AutoTokenizer\n\npeft_model_dir = \"peft-dialogue-summary\"\n\n# load base LLM model and tokenizer\ntrained_model = AutoPeftModelForCausalLM.from_pretrained(\n    peft_model_dir,\n    low_cpu_mem_usage=True,\n    torch_dtype=torch.float16,\n    load_in_4bit=True\n)\n\ntokenizer = AutoTokenizer.from_pretrained(peft_model_dir)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:04:19.758613Z","iopub.execute_input":"2024-07-30T11:04:19.759020Z","iopub.status.idle":"2024-07-30T11:05:11.249290Z","shell.execute_reply.started":"2024-07-30T11:04:19.758987Z","shell.execute_reply":"2024-07-30T11:05:11.248477Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"513eac916bd346ba9fcde469a8e05a51"}},"metadata":{}}]},{"cell_type":"code","source":"index = 51\n\ndialogue = train_data['article'][index][:10000]\nsummary = train_data['highlights'][index]\n\nprompt = f\"\"\"\nSummarize the following conversation.\n\n### Input:\n{dialogue}\n\n### Summary:\n\"\"\"\n\ninput_ids = tokenizer(prompt, return_tensors='pt',truncation=True).input_ids.cuda()\noutputs = trained_model.generate(input_ids=input_ids, max_new_tokens=200, )\noutput= tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{prompt}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'TRAINED MODEL GENERATED TEXT :\\n{output}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:05:11.250809Z","iopub.execute_input":"2024-07-30T11:05:11.251099Z","iopub.status.idle":"2024-07-30T11:05:37.190527Z","shell.execute_reply.started":"2024-07-30T11:05:11.251075Z","shell.execute_reply":"2024-07-30T11:05:37.189570Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nSummarize the following conversation.\n\n### Input:\nYou might expect polar bears, the Artic Circle's apex predators, to be dab hands at dancing on ice. But as this specimen in Svalbard shows, even after thousands of years of evolutionary adaptation, some still suffer from two-left feet on the frozen ocean. Heinrich Eggenfellner, a 49-year-old videographer from Norway, said: 'I have encountered polar bears many times every year since I live up here and am used to them. 'This episode, however, was extraordinary.' Born slippy: A polar walks across thin sea ice in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the slippery surface . Spreading its weight: The polar bear does its best not to collapse through the fragile ice by spreading out . In its element: The beast finally gave up and pushed a hole in the ice to dive into the freezing water . Mr Eggenfellner and his friend Svein Wik spent hours in Norway's northernmost territory hunting for a polar bear to film and photograph, then hours more waiting for the slumbering beast to wake up. It was time well spent. The patient duo were treated to a farcical display of slipping and sliding across the frozen sea, with their subject falling flat on its face at least once. 'Maybe we waited 3-4 hours before the bear woke up and came out onto thinner and thinner ice,' Mr Wik told Caters News Agency. 'At one point, it spread out on all four legs to prevent falling thorough the ice until finally the bear gave up, pushed through the ice and started to swim. 'He dived for a few seconds and showed up again, looking up and then started to shake of the water.' Proud: Polar bears are the Arctic Circle's apex predators and have adapted to the habitat over millennia . Evolution: Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice . Brains: However this beast seems to have realised that big feet are not enough to stop it smashing through the thin ice and is trying to spread its weight to lessen the pressure beneath it . Weighty: Polar bears can weigh up to 1,100lbs, more than enough to smash through thin layers of frozen sea . Taking a dip: The polar bear pictured just after deciding it was better off taking a swim in the freezing sea . Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice. They can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea that would easily hold a man. Mr Wik added: 'It is difficult to explain my feelings in situations like this. I think the Polar bear is one of the most charismatic animals in the world. 'It was a rare and very interesting situation to watch everything and this was, without doubt, the ultimate wilderness experience for me.' Stunning: Photographer Svein Wik and videographer Heinrich Eggenfellner spent hours trying to find a polar bear to document in the stark frozen landscape of Svalbard, the Norwegian Arctic territory .\n\n### Summary:\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\nPolar bears have evolved special large, flat paws for walking on sea ice .\nBut this specimen from Svalbard nevertheless struggled with its footing .\nThe Arctic killer ventured off the thick ice that can support his weight .\n\n---------------------------------------------------------------------------------------------------\nTRAINED MODEL GENERATED TEXT :\nPolar bear slips and slides across thin sea ice\n\nA polar bear struggles to stay upright on thin sea ice in Svalbard, Norway\n\nThe bear slips and slides across the thin ice before finally deciding to dive into the freezing sea\n\nPolar bears are regarded as marine mammals because of the many months they spend at sea\n\nTheir flat paws are designed to distribute their bulk as they pad across thin ice\n\nThe bear struggles to stay upright on the thin ice before finally deciding to dive into the freezing sea\n\nThe beast falls flat on its face at least once during the episode\n\nIt is difficult to explain my feelings in situations like this, says photographer Svein Wik\n\nThe beast finally gives up and pushes a hole in the ice to dive into the freezing water\n\nThe beast falls flat on its face\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}